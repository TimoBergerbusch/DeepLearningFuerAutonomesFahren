----------------------- REVIEW 2 ---------------------
PAPER: 32
TITLE: Comparison of Deep Learning Architectures on Simulated Environments
AUTHORS: Timo Bergerbusch
 
Overall evaluation: 2 (accept)
 
----------- Overall evaluation -----------
Summary:
The paper compares the Deep Learning Languages CNNArchLang, Caffe, Caffe2 ,and MxNet. A comparison between the deep learning approaches mediated perception, behavior reflex, and direct perception is also presented.
After convincing the reader of the importance of machine learning with CNNs in the automotive domain, a introduction to neural networks, convolutional neural networks, and the CNN architecture AlexNet is given.
Next, the four DLLs are introduced by explaining their syntax concepts, features, and drawbacks.
Then the three deep learning approaches and their respective world models(or lack theirof) are explained with an visual example for each.
After that, the implementation of AlexNet in CNNArchLang and Caffe is compared and the training process with the KITTI Dataset and TORCS is described.
In chapter 5 the direct perception approach is compared to the behavior reflex approach by evaluating the performance of both with TORCS and citing a similar comparision with the KITTI dataset.
The conclusion contains a table comparing the 4 DDLs in 16 data points.
 
typos/grammar:
+ [Further->Furthermore] we state scenarios
 
+ create an overview [over->of] the mentioned language
 
+ from parking or lane keeping assistant [->to] fully autonomous
 
+ been proven to be powerful enough to handle [such many-> this amount of] training iterations with
 
+ Therefore we introduce in ?? the three main approaches of using a CNN.
{missing reference}
 
+ [SLI -> multiple GPUs]
{unnecessary or unexplained technical term}
 
+ Therefore there is a need [of->for] specialized languages.
 
+ Also one wants to have simple build presets[->.]
 
+ (The whole description is based on[TvWH17] and especially [Tim18]) {no parentheses needed}
 
+ [MontiCar->MontiCAR]
 
+ One [very huge->] advantage of CNNArchLang
 
+ and have less verbose [->syntax] than most other languages
 
+ One important aspect
{used two times in a row}
 
+ Yangqing Jia during [hos->his] PhD at
 
+ simple compared to the in ?? mentioned mediated {missing reference}
 
+ explained in TODO
{open TODO}
 
+ For autonomous driving the training has to be [very intensively done-> rigorous]
 
+ the training is done using the KITTI dataset and also combine[s] two CNNs for near and far perception
 
+ Overall the most important aspect[s->] of state-of-the-art deep learning frameworks [are->is] the efficiency.
 
+ There a fleet of 100 cars is analyzed,[to estimate/collect?] how much useful data is produces during 1 year.
{meaning unclear}
 
 
 
Minor problems:
-Missing references
-1 open TODO in text
-Figure 1.2: consider small paragraph instead of long label 
-Section 1.2 is hard to understand, Figure similar to the one in section 1.1 would help 
-Figure 3.4 is never mentioned/explained
 
 
 
Major problems:
Chapter 3 and 5 are separated by unrelated chapter.
They are also disconnected from the rest of the paper(deep learning approaches are not mentioned in chapters 1,2,4,6)