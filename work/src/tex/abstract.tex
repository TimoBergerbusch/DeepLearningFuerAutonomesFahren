{\bf\Large Abstract} \\ [1em]
Deep learning (DL) came into the foreground of research after some stunning breakthroughs. Especially in image-recognition with novel Convolutional Neural Net (CNN) architectures, which made training on millions of images feasible on off-the-shelf GPUs. These advances are of high relevance to autonomous driving since much of the information for driving is visual.\\
In this paper we will give a general introduction to the topic of \nns (NNs) and then state the specialties defining CNNs, which is a subclass of NNs designed for the task of image analysis.\\
A multitude of frameworks and libraries has been created for DL using all kinds of languages. In case of neural network architectures, it is beneficial to take advantage of domain-specific languages (DSLs), to facilitate the development of new NNs.\\
Because of that, we will compare the different DSLs \cnnarch, \caffe, \caffetwo, and \mxnet, based on the factors of usability, scope of functionality, also regarding training possibilities, and the integration on a subject.\\
Regarding the task of autonomous driving, we distinguish between the three main paradigms currently used and researched for autonomous driving agents: mediated perception, behavior reflex, and direct perception.\\
We will analyze a CNN using the direct perception approach and compare it to state-of-the-art implementations of the other paradigms, training on a simulator \torcs or the \kitti database. Furthermore, we state scenarios probably causing problems for the direct perception approach. \\
Finally, we create an overview of the mentioned languages with a table, which states the functionalities and properties in a nutshell.
\cleardoublepage
