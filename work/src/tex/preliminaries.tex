\chapter{Preliminaries}

The field of autonomous driving agents has rapidly become a key factor in modern car manufacturing. Current research topic rises the agents from parking or lane keeping assistants to fully autonomous driving agents obeying the traffic rules and having the ability to react to the volatile environment in a reasonable way.

For that, machine learning techniques have proven themselves as an essential part. In order to fulfill the security standards and create a sophisticated agent, it has to be trained on hundred-thousands of scenarios, each having a large set of data attached, for example sensor and image data of multiple cameras.\\
The approach of \textit{Convolutional Neural Networks} (CNNs) have been proven to be powerful enough to handle this amount of training iterations with a huge number of input variables, while maintaining a large learning capacity. \cite{krizhevsky2012imagenet}

%In \Cref{chapter: DLL} we see that there is the need of specific languages for the design and implementation of such nets. We introduce four languages. Three are well known and established in the world of DSL and one is an upcoming new language.

%A CNN, as explained in \Cref{sec:CNN}, has a general structure, but can be altered, to fit into the approach, in various ways, influencing the result. Therefore we introduce in \Cref{chapter: Deep Learning Approaches} the three main approaches of using a CNN in the stated topic.
\section{Neural Networks}\label{sec: NN}

The \nns are a construct, adapted from biological processes. Its general structure is uncomplicated, but has immense expressiveness. The complete spectrum of what can be modeled by \nns is currently not known.\\
A neural net is made out of neurons and has one very basic function:\\
It takes a fixed number $n \in \mathbb{N}$ of the incoming values $x_i$, where the vector $(x_0,\dots x_n)^T$ is called a tensor, and multiplies them each with a specific weight $w_i$, where $0 \le i \le n$.
Also every neuron contains a bias $b$, which is a general value subtracted from the sum, so $\sum_{i=0}^{n} (x_i \cdot w_i) -b$. 

Often one applies an activation function to fix the value between 0 and 1. Such a function would be for example the sigmoid function \cite{von2016crc}, which is a non-linear functions. Without using a non-linear function one gets restricted to linear regression and therefore reduces their ability to model more complex functions. \cite{glorot2010understanding}
This non-linear normalized value is forwarded to the neurons of the next layer.

Those neurons are ordered in different layers, visualized in \Cref{fig: Simple NN}.
\begin{enumerate}
	\item input layer (green):\\ \label{item input layer}
	This layer gets fed with the input values of the problem, which can be for example sensor data or pixel color values.
	\item hidden layer (blue):\\\label{item hidden layer}
	The hidden layer consists of neurons receiving the values from the previous layer, while not being obliged to have the same number of neurons (c.f. \Cref{fig: Simple NN}).
	Different architectures can be distinguished to be deep (c.f. \Cref{fig: Deep Neural Net}). This means, that there are multiple hidden layers of neurons instead of just one. The number of neurons a layer contains is again independent of the previous layers.\\
	Also for the hidden layers, it is possible to be not fully connected (c.f. \Cref{fig: not fullyconnected Neural Net}). Thus some neurons do not forward their value to every neuron of the next layer.\\
	There is no rule dictating the best architecture, considering number of layers, neurons per layer or the connectivity.
	\item output layer (yellow):\\ \label{item output layer}
	The output neurons produce the value of the \nn. Depending on the \nns purpose it can be for example a confidence value of a classification, like recognizing a stop sign, or the value of changing the steering wheel angle. 
\end{enumerate}

In order to train a \nn one has to define the behavior the \nn should have. In an image classification example concerning traffic signs, one should know what the correct class of a given image of a sign is, i.e. a stop sign. Those are called labels.\\
A \nn can then be trained by giving it values for the input layer and comparing the values of the output layer with the solutions it should have resulted in. The difference can then be checked. Such a difference can be simply \texttt{true}/\texttt{false} or a value indicating how big the difference is.\\
In the example of signs: a classification of a ``speed limit 70''-sign as a ``speed limit 50''-sign is still wrong, but not as bad as the classification as a ``stop''-sign.\\
Using this difference values, the \nn can use backpropagation \cite{kinnebrock1994neuronale} to adjust the weights $w_i$ and biases $b$ to improve the output iteratively.

Further information about the underlying training algorithms like gradient descent, newtons method or conjugate gradient \cite{rojas2013theorie} is not given here in order to keep the paper in a justifiable length.  

\input{src/tex/neuralnets-tikz}
\section{Convolutional Neural Network (CNN)}\label{sec:CNN}

A CNN is a special class of deep feed-forward \nns. One of the main design goals of a CNN is, that they require a minimal amount of preprocessing. This is an important aspect, because they are often fed with images. Preprocessing high resolution images is very costly in terms of computational time. In the context of autonomous driving the time is even more crucial, since the driving agent needs to be able to react to spontaneous events.

Like most parts of \nns, also the CNNs are inspired by biological processes. It is mainly based on the connectivity pattern of an animals visual cortex, where special neurons respond only to stimuli of their receptive field, represented as rectangles lying in the image. Partial overlapping guarantees a complete coverage of the field of view. Those rectangles are often called kernel, feature or filters.\cite{matsugu2003subject}

%The partitioning into those rectangles can also have the advantage, that the size of the input image is not relevant. If there would be a direct correspondence of a pixel to one input value then a change of the size would infer null values or additional input values, where the weights are not directly well suited. But with partitioning it into sub-rectangles of the image the values can be unified by selecting these rectangles relative to the size.
%This is only given, if there are no fully connected layers. Otherwise one has to perform other steps like cropping, scaling or padding. %TODO ref

%Using the so called pooling the net reduces the amount of inputs by mapping a number of values, for example the color values of a kernel, to one single value. One often used pooling type is the max pooling, which takes the maximal value of a property. Using pooling and relative sizes of kernels one can avoid the necessity of equally sized images. \cite{wiki:CNN} 
The four basic layer types, which are mostly used for CNNs are:
\begin{enumerate}
\setlength{\itemindent}{-0.5cm}
\item fully-connected layers:\\
	equal to the fully connected layers described for \nns (c.f. \Cref{sec: NN})
\item convolutional layers:\\
	A convolutional layer compares the given image with a list of features, the net derived, to indicate a certain item. In this context it could be an other car driving ahead of the host. Those features are not a-priori given, but learned by the CNN. \\
	It is simple to understand using an example:\\
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[node distance = .5cm]
		\node(table1) {\begin{tabular}{|c|c|c|c|} \hline
			7 & 6 & 5 & 5 \\\hline
			6 & 9 & 1 & 3 \\\hline
			4 & 1 & 2 & 8 \\\hline
			2 & 9 & 3 & 1 \\\hline
		\end{tabular}};
		\node[right = of table1](plus) {$\oplus$};
		\node[right = of plus](kernel) {\begin{tabular}{|c|c|} \hline
			-1 & 2 \\\hline
			2 & 0 \\\hline
		\end{tabular}};
		\node[right = of kernel] (equals){$=$};
		\node[right = of equals] (result) {\begin{tabular}{|c|c|c|} \hline
			17 & 22 & 7\\\hline
			20 & -5 & 9\\\hline
			2 & 21 & 20\\\hline
		\end{tabular}};
	
	
		\draw [red,ultra thick,rounded corners] (-1.25,1) rectangle (0,0);
		\draw [green!75!black,ultra thick,rounded corners] (-0.6,0.5) rectangle (0.6,-0.5);
		
		\draw [red,ultra thick,rounded corners] (3.05,0.55) rectangle (4.45,-0.55);
		\draw [green!75!black,ultra thick,rounded corners] (3.0,0.6) rectangle (4.5,-0.6);
		
		\draw [red,ultra thick,rounded corners] (6.25,0.75) rectangle (7.1,0.25);
		\draw [green!75!black,ultra thick,rounded corners] (7.1,0.25) rectangle (7.9,-0.25);
		
		\end{tikzpicture}
	\end{figure}
	The left most is the input and the second one is the kernel. The result is computed as a piece-wise multiplication and then adding them up. The convolution can differ in kernel size and stride, which denotes the movement of the kernel. In the example we have a kernel of size $2\times2$ and a stride of 1.\\
	So for example (red case): $7\cdot(-1)+\cdot6\cdot2+\cdot6\cdot2+4\cdot0=17$\\
	The number now represents the similarity or likelihood of the feature to be in that position. Edge detection can be applied easily using such a layer. \cite{hubel1968receptive}
\item rectified linear units (ReLUs):\\
	Those ReLUs perform a normalization step, by applying the function $max(0,x)$ to every element $x$. So for the example:
	\begin{figure}[H]
		\centering
		\begin{tabular}{|c|c|c|} \hline
			17 & 22 & 7\\\hline
			20 & -5 & 9\\\hline
			2 & 21 & 20\\\hline
		\end{tabular}
		$\Rightarrow$
		\begin{tabular}{|c|c|c|} \hline
			17 & 22 & 7\\\hline
			20 & 0 & 9\\\hline
			2 & 21 & 20\\\hline
		\end{tabular}
	\end{figure}
	The main purpose of such a ReLU is to create the prerequisite of mathematical functions, only accepting non-negative values. Often researchers tend to use the function $ln(1+e^x)$ in order to have a differentiable approximation of ReLU. 
\item pooling layers:\\
	The pooling layer reduces the input by having a windows size, which is typically 2 or 3, and a stride, which is typically 2, and map the values within the window to one single value. In our example this is done using the maximum value.
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[node distance = .5cm]
		\node (input) {\begin{tabular}{|c|c|c|} \hline
			17 & 22 & 7\\\hline
			20 & 0 & 9\\\hline
			2 & 21 & 20\\\hline
		\end{tabular}};
		\node[right = 0.7cm of input] (arrow) {$\Rightarrow$};
		\node[right = of arrow] (result) {\begin{tabular}{|c|c|} \hline
			22 & 9 \\\hline
			21 & 20\\\hline
		\end{tabular}};
	
		\draw [red,ultra thick,rounded corners] (-1.25,0.8) rectangle (0.4,-0.3);
		\draw [green!75!black,ultra thick,rounded corners] (0.41,0.8) rectangle (2.06,-0.3);
		
		\draw [red,ultra thick,rounded corners] (3.32,0.5) rectangle (4.12,0);
		\draw [green!75!black,ultra thick,rounded corners] (4.16,0.5) rectangle (4.96,0);
		\end{tikzpicture}
	\end{figure}
	For the red case, the value 22 is the maximum of the window containing $\{17,22,20,0\}$. For the green case, the 9 calculated is the maximum of the window $\{7,9\}$ since through a stride of 2 the window in partially not contained in the input.
\end{enumerate}

The application of convolution and pooling has the advantage that it reduces the effort to train a CNN. The weights and biases of neurons of each receptive field are equal. This is reasonable since for example a speed limit road sign should be identified independent, whether it is located next to the road, like on a normal road, or above the road, like on an highway. \cite{lecun2015lenet}

%Further CNNs make strong and mostly correct assumptions about the nature of images, like stationary of statistics and locality of pixel dependencies. This leads to fewer connections and parameters, compared to a normal feed-forward neural net with similar sized layers, and therefore reduces the time it takes to be trained, while being only slightly worse in their best-performance. \cite{krizhevsky2012imagenet}

\section{AlexNet} \label{sec: AlexNet}

The \textit{\alexnet} was one of the best performing CNN architectures in 2012 and is still performing good enough to be used for various problems. It was originally trained on the ImageNet subsets of \texttt{ILSVRC-2010} and \texttt{ILSVRC-2012} \footnote{Further information: http://www.image-net.org/challenges/LSVRC/} and became famous, because of its result being way ahead of all other competitors.

A highly optimized GPU implementation of this architecture combined with innovative features is publicly available. Those features lead to performance improvement and shorter training time.\cite{krizhevsky2012imagenet}

An important note is that the original test is dated back to 2012 and therefore was used with an overall GPU memory of 6 GB, with which training took about six days. With modern hardware like new GPUs, SLI usage (having multiple GPUs) or even clusters, the training can be done faster, or the model can be trained with more data to improve performance. The improvement caused only by hardware can be roughly grasped through \cite{sze2017hardware}.

%\todo{maybe calc the possible speed up based on ``Hardware for Machine Learning''}

\begin{figure}[ht]
	\centering
%	\includegraphics[scale = 0.45]{src/pic/AlexNet-structure.PNG}
	\includegraphics[scale = 1.3]{src/pic/AlexNet-structure-simple.PNG}
	\caption{The \alexnet-architecture. It consists of 5 convolutional layers (at the beginning), and three fully-connected layers (at the end). \cite{han2017pre}
	\cite{krizhevsky2012imagenet}}
	\label{pic: AlexNet}
	%TODO redraw in simple
\end{figure}